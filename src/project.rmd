


## Introduction

!TODO

## Setup

```{r libraries}
library("dplyr")
library("ggplot2")
library("here")
library("purrr")
library("rpart")
library("statebins")
library("tidygeocoder")
library("leaflet")
library("gridExtra")
```

```{r load_dataset}
df <- read.csv(here("data", "heart_data.csv"))
```

```{r dataset_summary}
str(df)
```

## Data analysis

### Unimportant variables

!TODO

```{r remove_values}
df <- df |> select(-RemovedTeeth)
```

### Non-numeric values

!TODO

```{r na_count}
na_df <- df |>
  select(where(~ any(is.na(.) | . == ""))) |>
  mutate(across(where(is.character), ~ ifelse(. == "", NA, .))) |>
  mutate(across(where(is.character), as.factor)) %>%
  {
    tibble(column = names(.), na_count = colSums(is.na(.)))
  } |>
  filter(na_count > 0) |>
  arrange(desc(na_count))

ggplot(na_df, aes(x = column, y = na_count)) +
  geom_bar(
    stat = "identity",
    fill = "skyblue",
    position = "dodge"
  ) +
  labs(title = "NA Counts for Each Column") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90),
    axis.text.y = element_text(hjust = 1),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    plot.title = element_text(hjust = 0.5)
  ) +
  coord_flip()
```

### Data generation

Now we can use all the data in the dataset to predict the height and the weight
```{r fixing_weigh_weight_bmi}
weight_model <- rpart(WeightInKilograms ~ ., data = df, method = "anova")
height_model <- rpart(HeightInMeters ~ ., data = df, method = "anova")

# Predict WeightInKilograms for NA values
df$WeightInKilograms[is.na(df$WeightInKilograms)] <- predict(weight_model, newdata = df[is.na(df$WeightInKilograms), ])

# Predict HeightInMeters for NA values
df$HeightInMeters[is.na(df$HeightInMeters)] <- predict(height_model, newdata = df[is.na(df$HeightInMeters), ])
```

After predicting the values the BMI that were NA can be calculated and the `WeightInKilograms` and `HeightInMeters` are redundant and can be removed.
```{r}
df$BMI <- df$WeightInKilograms / (df$HeightInMeters^2)

# DEBUG
df |>
  select(where(~ any(is.na(.)))) |>
  mutate(across(where(is.character), as.factor)) |>
  summary()

df <- df |> select(-WeightInKilograms, -HeightInMeters)
```


### Variable recodifications

#### Age

- very young [0,25)
- young [25,35)
- mature [35,50)
- senior [50,65)
- old [65,80)
- very old [80,inf)

```{r age_bin}
df <- df |>
  mutate(
    AgeCategory = case_when(
      AgeCategory %in% c("Age 18 to 24") ~ "very young",
      AgeCategory %in% c("Age 25 to 29", "Age 30 to 34") ~ "young",
      AgeCategory %in% c("Age 35 to 39", "Age 40 to 44", "Age 45 to 49") ~ "mature",
      AgeCategory %in% c("Age 50 to 54", "Age 55 to 59", "Age 60 to 64") ~ "senior",
      AgeCategory %in% c("Age 65 to 69", "Age 70 to 74", "Age 75 to 79") ~ "old",
      AgeCategory %in% c("Age 80 or older") ~ "very old",
      AgeCategory == "" ~ "not known",
      TRUE ~ AgeCategory
    )
  ) |>
  mutate(AgeCategory = factor(
    AgeCategory,
    levels = c("very young", "young", "mature", "senior", "old", "very old", "not known")
  ))

df |> count(AgeCategory)

ggplot(df, aes(x = AgeCategory)) +
  geom_bar(
    stat = "count",
    fill = "skyblue",
    position = "dodge"
  ) +
  labs(title = "Age frequency distribution") +
  theme_minimal() +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    plot.title = element_text(hjust = 0.5)
  )
```

#### BMI

```{r BMI_bin}
# bmi_categories <- c("Underweight", "Normal Weight", "Overweight", "Obese", "Extremely Obese")
# bmi_ranges <- c(0, 18.5, 24.9, 29.9, 34.9, Inf)
#
# # Create a new column "BMICategory" based on BMI ranges
# df$BMI <- cut(df$BMI, breaks = bmi_ranges, labels = bmi_categories, include.lowest = TRUE)
```

#### Yes/No

```{r boolean_map}
bool_cols <- df |>
  select(where(~ any(. %in% c("Yes", "No")))) |>
  colnames()

for (col in bool_cols) {
  df[[col]] <- ifelse(df[[col]] == "No", 0, 1)
}
```

### Outlier elimination

!TODO

```{r outliers}
z_score_mask <- function(vec) {
  z_values <- abs((vec - mean(vec)) / sd(vec))

  return(z_values > 3)
}

iqr_mask <- function(vec) {
  q1 <- quantile(vec, .25, na.rm = TRUE)
  q3 <- quantile(vec, .75, na.rm = TRUE)
  iqr <- IQR(vec, na.rm = TRUE)

  return(vec < (q1 - 1.5 * iqr) | vec > (q3 + 1.5 * iqr))
}
```

### Duplicated observations

Good practice to remove duplicated rows before oversampling ! DO IT AFTER APLYING FEATURE ENGINEERING AND WHATNOT

```{r distinct_removal}
df <- unique(df)
cat("Removed", sum(duplicated(df)), "duplicated observations")
```


## Data visualization

```{r states_map_final}
# geocoded_data <- tibble(State = unique(df$State)) |> geocode("State")
#
# obs_counts <- table(df$State)
# # Add the Obs column to the geocoded_data
# geocoded_data$Obs <- obs_counts[match(geocoded_data$State, names(obs_counts))]
#
# # Merge latitude and longitude information into your_data
# map <- leaflet(data = geocoded_data) |>
#   addTiles() |>
#   addMarkers(
#     lng = ~long,
#     lat = ~lat,
#     popup = ~ paste("Number of observations: ", Obs)
#   ) |>
#   addLegend("bottomright", colors = "blue", labels = "Data Points")
#
# # Display the map
# map
```

```{r states_map_presentation, warning=FALSE}
state_counts <- table(df$State)

# Merge the counts with the original data
df_with_counts <- merge(
  df,
  data.frame(
    State = names(state_counts),
    Count = as.numeric(state_counts)
  ),
  by = "State",
  all.x = TRUE
)

# Plot the choropleth map using statebins_continuous
statebins(
  state_data = df_with_counts,
  state_col = "State",
  value_col = "Count"
) +
  labs(title = "Number of Observations in Each State") +
  theme_minimal() +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.line = element_blank(),
    plot.title = element_text(hjust = 0.5)
  )
```


```{r}
numeric_cols <- sapply(df, is.numeric)

# Create histograms for numeric columns on separate pages
par(mfcol = c(1, 1)) # Reset layout to default

for (col in names(df[, numeric_cols, drop = FALSE])) {
  hist(df[[col]], main = col, xlab = col, col = "lightblue", border = "black")
}
```
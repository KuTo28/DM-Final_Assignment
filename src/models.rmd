```{r}
model_accuracy <- function(model, train, test, characteristic) {
  fitted_model <- model |>
    fit(as.formula(paste(characteristic, "~ .")), data = train) # nolint

  pred <- fitted_model |>
    predict(test) |>
    pull(.pred_class) # nolint

  results <- test |>
    mutate(predictions = pred) |> # nolint
    metrics(truth = !!as.name(characteristic), estimate = predictions) |> # nolint
    filter(.metric %in% c("accuracy", "kap")) |> # nolint
    pivot_wider(names_from = .metric, values_from = .estimate) |> # nolint
    select(accuracy, kap) # nolint

  return(list("model" = fitted_model, "metrics" = as.data.frame(results)))
}
```

```{r}
library(tidymodels)
library(GGally)
library(here)
library(caret)
library(agua)
```

```{r}
df <- read.csv(here("data", "clean.csv"))
summary(df)
str(df)
```

## Data split

!TO_FORMAL We'll first separate the observations that contain a non numeric `HadHeartAttack` to predict its values in the future

```{r}
heart_attack_target <- df[is.na(df$HadHeartAttack), ] # 2116
df <- df[!is.na(df$HadHeartAttack), ]
df <- df |>
  select(-X) |>
  mutate(HadHeartAttack = as.factor(HadHeartAttack))
```

```{r}
set.seed(123)

had_heart_attack <- df[df$HadHeartAttack == 1, ]

# Undersample to the given target
had_not_heart_attack <- df[df$HadHeartAttack == 0, ] |>
  slice_sample(n = nrow(had_heart_attack))

df <- Reduce(
  function(x, y) merge(x, y, all = TRUE),
  list(had_heart_attack, had_not_heart_attack)
)
```

```{r data_split}
df_split <- initial_split(na.omit(df), prop = 0.70, strata = HadHeartAttack)
train <- training(df_split)
test <- testing(df_split)
```

```{r}
models <- list(
  logistic_reg(
    mode = "classification",
    engine = "glm",
  ),
  nearest_neighbor(
    mode = "classification",
    engine = "kknn",
    neighbors = 10
  ),
  svm_linear(
    mode = "classification",
    engine = "kernlab",
  ),
  svm_rbf(
    mode = "classification",
    engine = "kernlab",
  ),
  decision_tree(
    mode = "classification",
    engine = "rpart",
    tree_depth = 20
  ),
  rand_forest(
    mode = "classification",
    engine = "ranger"
  ),
  bart(
    mode = "classification",
    engine = "dbarts",
    trees = 100
  ),
  mars(
    mode = "classification",
    engine = "earth",
  ),
  mlp(
    mode = "classification",
    engine = "nnet",
    epochs = 100,
    hidden_units = 8,
    learn_rate = 0.01
  ),
  boost_tree(
    mode = "classification",
    engine = "xgboost",
    trees = 100,
    tree_depth = 10,
    min_n = 10,
    loss_reduction = 0.01,
    learn_rate = 0.01
  )
)

model_results <- map(models, ~ model_accuracy(
  .,
  train,
  test,
  "HadHeartAttack"
))
```

```{r model feature importance}
importance_log <- coef(models$logistic_reg)
importance_NN <- table(models$nearest_neighbor)
importance_SVMlinear <- coef(models$svm_linear)
importance_decision <- models$decision_tree$importance
importance_rand <- models$rand_forest$importance
```

## PCA

```{r sandbox}
df %>%
  summarise_all(~ sum(is.na(.))) %>%
  select_if(~ . > 0)
```

```{r}
hd_num <- mutate_if(df, is.character, as.factor)
hd_num <- mutate_if(hd_num, is.factor, as.numeric)

hd_num <- na.omit(hd_num)

str(hd_num)
pca_mod <- prcomp(hd_num[, -1], scale = TRUE)
cumsum(pca_mod$sdev / sum(pca_mod$sdev))[1:10]

plot(pca_mod$rotation[, 1:2], type = "n")
text(pca_mod$rotation[, 1:2], labels = (colnames(hd_num)[-1]))
```

## Linear Discriminant Analysis (LDA)

```{r}
lda <- model_accuracy(
  discrim_linear(
    mode = "classification",
    engine = "MASS",
  ),
  train |> mutate(HadHeartAttack = as.factor(HadHeartAttack)),
  test |> mutate(HadHeartAttack = as.factor(HadHeartAttack)),
  "HadHeartAttack"
)

lda$metrics
```

## Quadratic Discriminant Analysis (QDA)

```{r}
qda <- model_accuracy(
  discrim_quad(
    mode = "classification",
    engine = "MASS",
  ),
  train |> mutate(HadHeartAttack = as.factor(HadHeartAttack)),
  test |> mutate(HadHeartAttack = as.factor(HadHeartAttack)),
  "HadHeartAttack"
)

qda$metrics
```

## Naive Bayes

```{r}
nb <- model_accuracy(
  naive_Bayes(
    mode = "classification",
    engine = "klaR",
  ),
  train |> mutate(HadHeartAttack = as.factor(HadHeartAttack)),
  test |> mutate(HadHeartAttack = as.factor(HadHeartAttack)),
  "HadHeartAttack"
)

nb$metrics
```

## Asoociation rules

```{r}
str(df)
```

```{r}
df2 <- data.frame(lapply(df, as.factor))
df2 <- as(df2, "transactions")
```

```{r}
run_apriori_with_loop <- function(df2, supp_values, conf_values, minlen_values, verbose = FALSE) {
  result_df <- data.frame()

  for (supp_val in supp_values) {
    for (conf_val in conf_values) {
      for (minlen_val in minlen_values) {
        if (verbose) {
          print(paste("[INFO] ", "Support:", supp_val, "Confidence:", conf_val, "MinLength:", minlen_val))
        }
        rules <- apriori(
          df2,
          parameter = list(
            supp = supp_val,
            conf = conf_val,
            minlen = minlen_val
          ),
          appearance = list(rhs = c("HadHeartAttack=1", "HadHeartAttack=0")),
          control = list(verbose = FALSE)
        )
        if (length(rules) == 0) { next }
        red_rules <- rules
        not_red_rules <- rules[!is.redundant(rules)]
        rules_conf <- sort(not_red_rules, by = "lift", decreasing = TRUE)

        # Print if there are rules where rhs = HeartAttack=1
        if (length(rules_conf[rules_conf@rhs %in% "HadHeartAttack=1"]) > 0) {
          if (verbose) {
            print(paste("[INFO YES SIRRR] ", "Support:", supp_val, "Confidence:", conf_val, "MinLength:", minlen_val))
            print(rules_conf[rules_conf@rhs %in% "HadHeartAttack=1"])
          }
        }

        result_df <- rbind(
          result_df,
          data.frame(
            Support = supp_val,
            Confidence = conf_val,
            MinLength = minlen_val,
            NumRedundant_Rules = length(red_rules),
            NumNon_Redundant_Rules = length(rules_conf)
          )
        )
      }
    }
  }

  return(result_df)
}
```

```{r}
supp_values <- c(0.3, 0.4)
conf_values <- c(0.6, 0.7, 0.8, 0.9)
minlen_values <- c(2, 3)

result_rules <- run_apriori_with_loop(
  df2,
  supp_values,
  conf_values,
  minlen_values,
  verbose = TRUE
)
result_rules
```

```{r}
df3 <- read.csv(here("data", "clean.csv"))
df3 <- data.frame(lapply(df3, as.factor))
df3 <- as(df3, "transactions")
```


```{r}
#checking subsets of size 1 2 3 4Warning: Mining stopped (time limit reached). Only patterns up to a length of 4 returned! done [7.39s].
rules <- apriori(
  df3,
  parameter = list(
    supp = 0.3,
    conf = 0.6,
    minlen = 2,
    maxlen = 8,
    maxtime = 1000
  ),
  appearance = list(rhs = c("HadHeartAttack=1", "HadHeartAttack=0")),
)
#inspect(rules)

# PRint the rules with onoly HadHeartAttack=1
rules_conf <- sort(rules, by = "lift", decreasing = TRUE)
inspect(rules_conf[rules_conf@rhs %in% "HadHeartAttack=1"])
```

Support=0.3, Confidence=0.6, MinLength=2
Support=0.3, Confidence=0.6, MinLength=3